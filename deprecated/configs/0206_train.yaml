model_configuration:
    attention_heads: 8
    d_model: 512
    ff_dim: 2048
    dropout: 0.1
    transformer_decoder_only: False
    encoder_layers: 3
    decoder_layers: 3
image_specs: 
    img_feature_channels: 1280
embedding:
    size: 512
    embedding_dim: 512

vocab_size: None
max_len: 100
mixed_precision: True
gradient_clip: 0.1
img_size: 400

img_dir: "/mount/images"
smiles_dir: "/mount/smiles_cleansed"
vocab_dir: "/mount/TOKENMAP_seed_3609_max200smiles.json"

test: False
batch_size: 28
num_workers: 32
device: "cuda"
lr: 0.0001
weight_decay: 0.000001
num_epochs: 10
seed: 42
save_interval: 100
eval_interval: 10

decoder_lr_factor: 10
scheduler: "CosineAnnealingWarmUpRestarts"
# scheduler: "CosineAnnealing"

# cosine annealing
T_max: 10000
eta_min: 0

# cosine annealing warmup restart
T_0: 10000
T_mult: 2
eta_max: 0.001
T_up: 50
gamma: 0.9

state_dict_dir: "/mount/KMolOCR/ckpt/2024-02-06_6_40_42/1_2.pt"
load_optimizer: False
eval_first: False

partial_training: False
    # train_part: 'decoder'
# utils
# overall debugging